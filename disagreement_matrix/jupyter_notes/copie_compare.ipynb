{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af89aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import re\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import scipy.stats as ss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.io\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "from numpy import percentile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "# Import all models\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "from IPython.display import display\n",
    "\n",
    "# dataset path\n",
    "data_path = \"/Users/kadima/experiment_any/anomaly-detection/datasets_resend/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a88244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_dict = dict()\n",
    "label_dict = dict()\n",
    "\n",
    "for root, path, files in os.walk(\"../datasets_resend/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"txt\"):\n",
    "            if \"label\" not in file:\n",
    "                with open(root+file,'r') as d:\n",
    "                    data = d.readlines()\n",
    "                    data = [x.split() for x in data]\n",
    "                    data = [[float(i) for i in x] for x in data]\n",
    "                training_dict[file] = data\n",
    "            else:\n",
    "                with open(root+file,'r') as d:\n",
    "                    label = d.readlines()\n",
    "                    label = [int(x[0]) for x in label ]\n",
    "                label_dict[file] = label\n",
    "\n",
    "\n",
    "def sd_thresholder(scores, real_y, factor=2.5):\n",
    "    high_limit = np.mean(scores) + factor * np.std(scores)\n",
    "    y_predict = scores >= high_limit\n",
    "    y_predict = [1 if j else 0 for j in y_predict]\n",
    "    f1 = f1_score(real_y, y_predict)\n",
    "    return y_predict, f1, high_limit\n",
    "\n",
    "\n",
    "def mad_thresholder(scores, real_y):\n",
    "    median_ = np.median(scores)\n",
    "    mad = 1.4826 * np.median(np.abs(scores - median_))\n",
    "    y_predict = scores >= 3 * mad\n",
    "    y_predict = [1 if j else 0 for j in y_predict]\n",
    "    f1 = f1_score(real_y, y_predict)\n",
    "    return y_predict, f1, 3 * mad\n",
    "\n",
    "\n",
    "def iqr_thresholder(scores, real_y):\n",
    "    iqr = np.percentile(scores, 75) - np.percentile(scores, 25)\n",
    "    y_predict = scores >= (np.percentile(scores, 75) + 1.5 * iqr)\n",
    "    y_predict = [1 if j else 0 for j in y_predict]\n",
    "    f1 = f1_score(real_y, y_predict)\n",
    "    return y_predict, f1, np.percentile(scores, 75) + 1.5 * iqr\n",
    "\n",
    "\n",
    "# the disagreement_v1 removes min rank and max rank in disagreement matrix and get the row's standard deviation.\n",
    "# the simplest way\n",
    "def disagreement_v1(score_matrix, num_detectors, real_y):\n",
    "    rank_matrix = np.zeros([len(score_matrix), num_detectors])\n",
    "    for i in range(num_detectors):\n",
    "        # rank by each column and get its rank_position\n",
    "        rank_matrix[:, i] = ss.rankdata(score_matrix[:, i])\n",
    "    std_record = np.zeros(len(X))\n",
    "    rank_record = []\n",
    "    for i in range(len(score_matrix)):\n",
    "        rank_rows = rank_matrix[i, :]\n",
    "        min_ = np.min(rank_rows)\n",
    "        max_ = np.max(rank_rows)\n",
    "        rank_rows = [x for x in rank_rows if x not in [min_, max_]]\n",
    "        std_record[i] = np.std(rank_rows)\n",
    "        rank_record.append(rank_rows)\n",
    "    valid_rank_rows = []\n",
    "    for i in range(len(score_matrix)):\n",
    "        num_large = np.sum(np.array(rank_record[i]) >= len(score_matrix) // 3)\n",
    "        if num_large >= num_detectors // 3:\n",
    "            valid_rank_rows.append(i)\n",
    "    std_max_rows = np.argsort(np.array(std_record)[valid_rank_rows])[-1:]\n",
    "    std_median_scores = np.median(score_matrix[std_max_rows, :], axis=0)\n",
    "    threshold_for_each_detector = std_median_scores\n",
    "\n",
    "    f1_list = []\n",
    "    for i in range(num_detectors):\n",
    "        outliers_rows = score_matrix[:, i] >= threshold_for_each_detector[i]\n",
    "        y_predict = [1 if j else 0 for j in outliers_rows]\n",
    "        f1 = f1_score(real_y, y_predict)\n",
    "        f1_list.append(f1)\n",
    "    return f1_list, threshold_for_each_detector, std_record\n",
    "\n",
    "\n",
    "# 取 disagreement matrix 的std\n",
    "def disagreement_v2(score_matrix, num_detectors, real_y, remove_extreme=False):\n",
    "    # normalize the score_matrix\n",
    "    origin_score_matrix = score_matrix.copy()\n",
    "    score_matrix = RobustScaler().fit_transform(score_matrix)\n",
    "\n",
    "    # get rank matrix\n",
    "    rank_matrix = np.zeros([len(score_matrix), num_detectors])\n",
    "    for i in range(num_detectors):\n",
    "        # rank by each column and get its rank_position\n",
    "        rank_matrix[:, i] = ss.rankdata(score_matrix[:, i], 'ordinal')\n",
    "    std_record = np.zeros(len(score_matrix))\n",
    "\n",
    "    # form a matrix for each row\n",
    "    for row_idx in range(len(score_matrix)):\n",
    "        tmp_matrix = np.zeros([num_detectors, num_detectors])\n",
    "        for col_idx in range(num_detectors):\n",
    "            rank_refer = rank_matrix[row_idx, col_idx]\n",
    "            for col_idx_2 in range(num_detectors):\n",
    "                if col_idx_2 == col_idx:\n",
    "                    tmp_matrix[col_idx, col_idx_2] = 0\n",
    "                else:\n",
    "                    target_row = np.argwhere(rank_matrix[:, col_idx_2] == rank_refer)\n",
    "                    target_row = target_row[0][0]\n",
    "                    curr_score = score_matrix[row_idx, col_idx_2]\n",
    "                    refer_score = score_matrix[target_row, col_idx_2]\n",
    "                    tmp_matrix[col_idx, col_idx_2] = curr_score - refer_score\n",
    "\n",
    "        if remove_extreme:\n",
    "            tmp_matrix_row_std = np.std(tmp_matrix, axis=1)\n",
    "            tmp_matrix_col_std = np.std(tmp_matrix, axis=0)\n",
    "            max_std_row = np.argmax(tmp_matrix_row_std)\n",
    "            max_std_col = np.argmax(tmp_matrix_col_std)\n",
    "            # skip the max one\n",
    "            robust_tmp_matrix = tmp_matrix[[i_ for i_ in range(num_detectors) if i_ != max_std_row], :]\n",
    "            robust_tmp_matrix = robust_tmp_matrix[:, [i_ for i_ in range(num_detectors) if i_ != max_std_col]]\n",
    "\n",
    "\n",
    "        else:\n",
    "            robust_tmp_matrix = tmp_matrix\n",
    "\n",
    "        std_record[row_idx] = np.mean(abs(robust_tmp_matrix))\n",
    "\n",
    "    std_max_row = np.argmax(std_record)\n",
    "    threshold_for_each_detector = score_matrix[std_max_row, :]\n",
    "    origin_threshold = origin_score_matrix[std_max_row, :]\n",
    "    f1_list = []\n",
    "\n",
    "    for i in range(num_detectors):\n",
    "        outliers_rows = score_matrix[:, i] >= threshold_for_each_detector[i]\n",
    "        y_predict = [1 if j else 0 for j in outliers_rows]\n",
    "        f1 = f1_score(real_y, y_predict)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return f1_list, origin_threshold, std_record\n",
    "\n",
    "\n",
    "# 取detector 自己的 disagreement\n",
    "def disagreement_v3(score_matrix, num_detectors, real_y, remove_extreme=False):\n",
    "    # normalize the score_matrix\n",
    "    score_matrix = RobustScaler().fit_transform(score_matrix)\n",
    "\n",
    "    # get rank matrix\n",
    "    rank_matrix = np.zeros([len(score_matrix), num_detectors])\n",
    "    for i in range(num_detectors):\n",
    "        # rank by each column and get its rank_position\n",
    "        rank_matrix[:, i] = ss.rankdata(score_matrix[:, i], 'ordinal')\n",
    "    std_record = np.zeros((len(score_matrix), num_detectors))\n",
    "\n",
    "    # form a matrix for each row\n",
    "    for row_idx in range(len(score_matrix)):\n",
    "        tmp_matrix = np.zeros([num_detectors, num_detectors])\n",
    "        for col_idx in range(num_detectors):\n",
    "            rank_refer = rank_matrix[row_idx, col_idx]\n",
    "            col_increment = 0\n",
    "            for col_idx_2 in range(num_detectors):\n",
    "                target_row = np.argwhere(rank_matrix[:, col_idx_2] == rank_refer)\n",
    "                target_row = target_row[0][0]\n",
    "                curr_score = score_matrix[row_idx, col_idx_2]\n",
    "                refer_score = score_matrix[target_row, col_idx_2]\n",
    "                tmp_matrix[col_idx, col_increment] = curr_score - refer_score\n",
    "                col_increment += 1\n",
    "\n",
    "        if remove_extreme:\n",
    "            tmp_matrix_row_std = np.std(tmp_matrix, axis=1)\n",
    "            tmp_matrix_col_std = np.std(tmp_matrix, axis=0)\n",
    "            max_std_row = np.argmax(tmp_matrix_row_std)\n",
    "            max_std_col = np.argmax(tmp_matrix_col_std)\n",
    "            # skip the max one\n",
    "            robust_tmp_matrix = tmp_matrix[[i_ for i_ in range(num_detectors) if i_ != max_std_row], :]\n",
    "            robust_tmp_matrix = robust_tmp_matrix[:, [i_ for i_ in range(num_detectors) if i_ != max_std_col]]\n",
    "        else:\n",
    "            robust_tmp_matrix = tmp_matrix\n",
    "\n",
    "        detector_disagreement = []\n",
    "        for j_ in range(num_detectors):\n",
    "            std_record[row_idx, j_] = np.mean(np.abs(np.concatenate((robust_tmp_matrix[j_, :],\n",
    "                                                                     robust_tmp_matrix[:, j_]),\n",
    "                                                                    axis=None)))\n",
    "\n",
    "    std_max_row = np.argmax(std_record, axis=0)\n",
    "    threshold_for_each_detector = score_matrix[std_max_row, np.arange(num_detectors)]\n",
    "    f1_list = []\n",
    "\n",
    "    for i in range(num_detectors):\n",
    "        outliers_rows = score_matrix[:, i] >= threshold_for_each_detector[i]\n",
    "        y_predict = [1 if j else 0 for j in outliers_rows]\n",
    "        f1 = f1_score(real_y, y_predict)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    return f1_list, threshold_for_each_detector, std_record\n",
    "\n",
    "\n",
    "def get_score_matrix(X, num_detectors):\n",
    "    return np.zeros([X.shape[0], num_detectors])\n",
    "\n",
    "def get_perform_matrix(num_thresholders, num_detectors):\n",
    "    return np.zeros((num_thresholders, num_detectors))\n",
    "\n",
    "\n",
    "random_state = np.random.RandomState(10)\n",
    "outliers_fraction = 0.4\n",
    "\n",
    "\n",
    "# initialize a set of detectors for LSCP\n",
    "classifiers = {\n",
    "    'Angle-based Outlier Detector (ABOD)':\n",
    "        ABOD(contamination=outliers_fraction),\n",
    "    # 'Cluster-based Local Outlier Factor (CBLOF)':\n",
    "    #     CBLOF(contamination=outliers_fraction,\n",
    "    #           check_estimator=False, random_state=random_state),\n",
    "    'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
    "        contamination=outliers_fraction),\n",
    "    'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                random_state=random_state, n_estimators=280),\n",
    "    'K Nearest Neighbors (KNN)': KNN(\n",
    "        contamination=outliers_fraction),\n",
    "    'Average KNN': KNN(method='mean',\n",
    "                       contamination=outliers_fraction),\n",
    "    'Local Outlier Factor (LOF)':\n",
    "        LOF(n_neighbors=35, contamination=outliers_fraction),\n",
    "    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),\n",
    "    'Principal Component Analysis (PCA)': PCA(\n",
    "        contamination=outliers_fraction, random_state=random_state),\n",
    "    \"COPOD\": COPOD()\n",
    "}\n",
    "\n",
    "names = []\n",
    "# Show all detectors\n",
    "for i, clf in enumerate(classifiers.keys()):\n",
    "    names.append(clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d42ffdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuttle_withoutdupl_v01_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "Stamps_withoutdupl_09_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "InternetAds_withoutdupl_norm_19_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "WBC_v01_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Pima_withoutdupl_35_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "Hepatitis_withoutdupl_16_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "thyroid_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "mnist_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "cover_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "breastw_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Lymphography_withoutdupl_catremoved_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Waveform_withoutdupl_v01_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "PageBlocks_withoutdupl_09_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "Arrhythmia_withoutdupl_46_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n",
      "Histogram-base Outlier Detection (HBOS)\n",
      "Isolation Forest\n",
      "K Nearest Neighbors (KNN)\n",
      "Average KNN\n",
      "Local Outlier Factor (LOF)\n",
      "One-class SVM (OCSVM)\n",
      "Principal Component Analysis (PCA)\n",
      "COPOD\n",
      "\n",
      "\n",
      "\n",
      "ecoli_data.txt\n",
      "Angle-based Outlier Detector (ABOD)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r8/hty9jhys3yl0s79tm9kc85x40000gp/T/ipykernel_4555/478599303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_data_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/r8/hty9jhys3yl0s79tm9kc85x40000gp/T/ipykernel_4555/478599303.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(X, y, classifiers)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# fit the data and tag outliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mclfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mscores_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyod/models/abod.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# validate inputs X and y (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Fit the models with the generated data and\n",
    "# compare model performances\n",
    "def get_result(X, y, classifiers):\n",
    "    threshold_records = list()\n",
    "    # create matrix to store the performance\n",
    "    score_matrix = get_score_matrix(X, len(classifiers.keys()))\n",
    "    perform_table = get_perform_matrix(5, len(classifiers.keys()))\n",
    "\n",
    "    np.random.seed(5)\n",
    "    clfs = []\n",
    "    # Fit the model\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        #         print(i + 1, 'fitting', clf_name)\n",
    "        # fit the data and tag outliers\n",
    "        print(clf_name)\n",
    "        clf.fit(X)\n",
    "        clfs.append(clf)\n",
    "        scores_pred = clf.decision_function(X)\n",
    "        score_matrix[:, i] = scores_pred\n",
    "\n",
    "    for i, thresholder in enumerate([sd_thresholder, mad_thresholder,\n",
    "                                     iqr_thresholder]):\n",
    "        kk = []\n",
    "        for j in range(score_matrix.shape[1]):\n",
    "            _, perform_table[i, j], b = thresholder(score_matrix[:, j], y)\n",
    "            kk.append(b)\n",
    "\n",
    "        threshold_records.append(kk)\n",
    "\n",
    "    for i in range(score_matrix.shape[1]):\n",
    "        perform_table[-2, i] = f1_score(y, clfs[i].predict(X))\n",
    "\n",
    "    perform_table[-1, :], a, dist_ = disagreement_v2(score_matrix, len(classifiers), y, True)\n",
    "    threshold_records.append(a)\n",
    "\n",
    "    return (pd.DataFrame(perform_table, columns=names, index=[\"sd\", 'mad', 'iqr', 'default', 'disagreement']),\n",
    "            threshold_records, dist_, score_matrix)\n",
    "\n",
    "result_dict = dict()\n",
    "\n",
    "for data_name, X in training_dict.items():\n",
    "    y_data_name = data_name[:-8] + \"label.txt\"\n",
    "    print(data_name)\n",
    "    if y_data_name in label_dict.keys():\n",
    "        y = np.asarray(label_dict[y_data_name])\n",
    "    X = np.asarray(X).astype(np.float64)\n",
    "    result_dict[data_name] = get_result(X, y, classifiers)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "print(\"Training process done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb1ea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan],\n",
       " [nan, nan, nan, nan, nan, nan, nan]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " training_dict[\"ecoli_data.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52bc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
